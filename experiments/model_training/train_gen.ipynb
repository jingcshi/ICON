{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371e4970-b607-49a2-af82-ccaa7a2fd9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from ellement.transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import Dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa7b7ce6-d23a-445e-9f01-a57c68f7b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = './../../data/gen/ebay_us-train.csv'\n",
    "test_data_path = './../../data/gen/ebay_us-test.csv'\n",
    "# model_checkpoint = 'google/flan-t5-xl'\n",
    "model_checkpoint = '/data/ebay-slc-a100/data/jingcshi/ICON_models/gen/flan-t5-xl-sota'\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "num_train_epochs = 10\n",
    "lr = 2e-5\n",
    "lr_schedule='linear'\n",
    "max_gen_length = 64\n",
    "np.random.seed(114514)\n",
    "torch.manual_seed(114514)\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acd9d6b5-3fd1-4a36-949e-7ba434e88792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7e50e8e07045efb8350d69624a6580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint,model_max_length=128)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n",
    "bertscore = evaluate.load('bertscore')\n",
    "gleu_score = evaluate.load(\"google_bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147f7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    model_inputs = tokenizer(examples[\"text\"])\n",
    "    labels = tokenizer(examples[\"summary\"])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0460d703-a242-4e6b-8d4a-12dc8c518275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    gleu = gleu_score.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])\n",
    "    bscore = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang='en')\n",
    "    bscore['Bs-P'] = np.mean(np.array(bscore.pop('precision'))).round(6)\n",
    "    bscore['Bs-R'] = np.mean(np.array(bscore.pop('recall'))).round(6)\n",
    "    bscore['Bs-F1'] = np.mean(np.array(bscore.pop('f1'))).round(6)\n",
    "    bscore.pop('hashcode')\n",
    "    result = {**bscore, **gleu}\n",
    "    return {k: round(v, 6) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c6ad37-c4cb-446f-8e50-8aaa6fcebdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc49346b6d34b06b4e56717d6e0fda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20993 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4c2730fa884082b7d262950da4e653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2333 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_data_path)\n",
    "eval_data = pd.read_csv(test_data_path)\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "eval_dataset = Dataset.from_pandas(eval_data)\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "eval_dataset = eval_dataset.map(tokenize, batched=True)\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\",\"labels\"])\n",
    "eval_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\",\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32ceabf9-c6eb-4ba4-8482-43b507533c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "timestr = now.strftime('%Y%m%d-%H%M')\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"/data/ebay-slc-a100/data/jingcshi/ICON_models/gen/{model_name}_{timestr}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=lr,\n",
    "    lr_scheduler_type=lr_schedule,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=8,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    generation_max_length=max_gen_length,\n",
    "    predict_with_generate=True,\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch'\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c05dc2-d61f-4a2f-9a2e-e66dc6150eef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10504' max='10504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10504/10504 2:34:55, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bs-p</th>\n",
       "      <th>Bs-r</th>\n",
       "      <th>Bs-f1</th>\n",
       "      <th>Google Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.534800</td>\n",
       "      <td>0.231220</td>\n",
       "      <td>0.976946</td>\n",
       "      <td>0.975041</td>\n",
       "      <td>0.975907</td>\n",
       "      <td>0.636584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.162499</td>\n",
       "      <td>0.981803</td>\n",
       "      <td>0.980650</td>\n",
       "      <td>0.981163</td>\n",
       "      <td>0.696640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.184700</td>\n",
       "      <td>0.136677</td>\n",
       "      <td>0.984200</td>\n",
       "      <td>0.983350</td>\n",
       "      <td>0.983723</td>\n",
       "      <td>0.735850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.138200</td>\n",
       "      <td>0.118561</td>\n",
       "      <td>0.985128</td>\n",
       "      <td>0.984599</td>\n",
       "      <td>0.984815</td>\n",
       "      <td>0.755820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.112400</td>\n",
       "      <td>0.114898</td>\n",
       "      <td>0.986430</td>\n",
       "      <td>0.985981</td>\n",
       "      <td>0.986162</td>\n",
       "      <td>0.777375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.115332</td>\n",
       "      <td>0.987039</td>\n",
       "      <td>0.986568</td>\n",
       "      <td>0.986761</td>\n",
       "      <td>0.787733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.113020</td>\n",
       "      <td>0.987300</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.987033</td>\n",
       "      <td>0.792457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.112417</td>\n",
       "      <td>0.987413</td>\n",
       "      <td>0.987106</td>\n",
       "      <td>0.987220</td>\n",
       "      <td>0.796414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10504, training_loss=0.18645494872163654, metrics={'train_runtime': 9297.6444, 'train_samples_per_second': 18.063, 'train_steps_per_second': 1.13, 'total_flos': 1.4368585553097523e+17, 'train_loss': 0.18645494872163654, 'epoch': 8.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_outputs = trainer.train()\n",
    "now = datetime.now()\n",
    "timestr = now.strftime('%Y%m%d-%H%M')\n",
    "training_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98512365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1113143041729927, 'eval_Bs-P': 0.987661, 'eval_Bs-R': 0.987425, 'eval_Bs-F1': 0.987502, 'eval_google_bleu': 0.801726}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asian Travel Maps[SEP]Travel Accessories[SEP]T...</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bathroom Shelves[SEP]Bath Towels &amp; Washcloths</td>\n",
       "      <td>Bathroom Supplies &amp; Accessories</td>\n",
       "      <td>Bathroom Supplies &amp; Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Collectible Police Handcuffs &amp; Keys[SEP]Collec...</td>\n",
       "      <td>Police Collectibles</td>\n",
       "      <td>Police Collectibles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other Horse Wear[SEP]Horse Lead Ropes[SEP]Equi...</td>\n",
       "      <td>Equestrian Equipment</td>\n",
       "      <td>Horse Wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pliers[SEP]Routers &amp; Joiners</td>\n",
       "      <td>Hand Tools</td>\n",
       "      <td>Tools &amp; Workshop Equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>Queen (Musical Artist) Apparel[SEP]Other Queen...</td>\n",
       "      <td>Root Concept</td>\n",
       "      <td>Root Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>Nail Treatment Creams[SEP]Nail Strengtheners[S...</td>\n",
       "      <td>Root Concept</td>\n",
       "      <td>Root Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>Industrial Anvils[SEP]Industrial Woodworking V...</td>\n",
       "      <td>Root Concept</td>\n",
       "      <td>Root Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>Collectible Postcards[SEP]Collectible Topograp...</td>\n",
       "      <td>Root Concept</td>\n",
       "      <td>Root Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>Metalworking Tumblers &amp; Media[SEP]Metalworking...</td>\n",
       "      <td>Root Concept</td>\n",
       "      <td>Root Concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2333 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input  \\\n",
       "0     Asian Travel Maps[SEP]Travel Accessories[SEP]T...   \n",
       "1         Bathroom Shelves[SEP]Bath Towels & Washcloths   \n",
       "2     Collectible Police Handcuffs & Keys[SEP]Collec...   \n",
       "3     Other Horse Wear[SEP]Horse Lead Ropes[SEP]Equi...   \n",
       "4                          Pliers[SEP]Routers & Joiners   \n",
       "...                                                 ...   \n",
       "2328  Queen (Musical Artist) Apparel[SEP]Other Queen...   \n",
       "2329  Nail Treatment Creams[SEP]Nail Strengtheners[S...   \n",
       "2330  Industrial Anvils[SEP]Industrial Woodworking V...   \n",
       "2331  Collectible Postcards[SEP]Collectible Topograp...   \n",
       "2332  Metalworking Tumblers & Media[SEP]Metalworking...   \n",
       "\n",
       "                           Prediction                        Reference  \n",
       "0                              Travel                           Travel  \n",
       "1     Bathroom Supplies & Accessories  Bathroom Supplies & Accessories  \n",
       "2                 Police Collectibles              Police Collectibles  \n",
       "3                Equestrian Equipment                       Horse Wear  \n",
       "4                          Hand Tools       Tools & Workshop Equipment  \n",
       "...                               ...                              ...  \n",
       "2328                     Root Concept                     Root Concept  \n",
       "2329                     Root Concept                     Root Concept  \n",
       "2330                     Root Concept                     Root Concept  \n",
       "2331                     Root Concept                     Root Concept  \n",
       "2332                     Root Concept                     Root Concept  \n",
       "\n",
       "[2333 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = trainer.evaluation_loop(\n",
    "            trainer.get_eval_dataloader(eval_dataset),\n",
    "            description=\"Evaluation\"\n",
    "        )\n",
    "preds = np.where(output.predictions != -100, output.predictions, tokenizer.pad_token_id)\n",
    "predictions = tokenizer.batch_decode(preds, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "eval_result_table = pd.DataFrame({'Input':list(map(lambda string: string[11:], eval_dataset['text'])), # Strip the \"summarize: \" prefix\n",
    "                                'Prediction': predictions, \n",
    "                                'Reference': eval_dataset['summary']})\n",
    "print(output.metrics)\n",
    "eval_result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e495d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_table.to_csv(f'./../evaluation/results/gen/{model_name}_{timestr}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
