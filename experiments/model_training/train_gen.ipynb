{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e4970-b607-49a2-af82-ccaa7a2fd9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + '/..')\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, Seq2SeqTrainer\n",
    "from datasets import Dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b7ce6-d23a-445e-9f01-a57c68f7b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = './../data/gen/google-train.csv'\n",
    "test_data_path = './../data/gen/google-train.csv'\n",
    "model_checkpoint = \"/data2T/jingchuan/untuned/flan-t5-base/\"\n",
    "model_name = model_checkpoint.split(\"/\")[-2]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_batch_size = 8\n",
    "eval_batch_size = 32\n",
    "num_train_epochs = 8\n",
    "lr = 1e-5\n",
    "lr_schedule='linear'\n",
    "max_gen_length = 64\n",
    "np.random.seed(114514)\n",
    "torch.manual_seed(114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd9d6b5-3fd1-4a36-949e-7ba434e88792",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seqmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint,model_max_length=128)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=seq2seqmodel,padding=True)\n",
    "bertscore = evaluate.load('bertscore')\n",
    "gleu_score = evaluate.load(\"google_bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f8726-5c82-412a-9e12-e5d612ee5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    model_inputs = tokenizer(examples[\"text\"])\n",
    "    labels = tokenizer(examples[\"summary\"])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460d703-a242-4e6b-8d4a-12dc8c518275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    gleu = gleu_score.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])\n",
    "    gleu['Gleu'] = gleu.pop('google_bleu')\n",
    "    bscore = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang='en')\n",
    "    bscore['Bs-P'] = np.mean(np.array(bscore.pop('precision'))).round(6)\n",
    "    bscore['Bs-R'] = np.mean(np.array(bscore.pop('recall'))).round(6)\n",
    "    bscore['Bs-F1'] = np.mean(np.array(bscore.pop('f1'))).round(6)\n",
    "    bscore.pop('hashcode')\n",
    "    result = {**bscore, **gleu}\n",
    "    return {k: round(v, 6) for k, v in result.items()}\n",
    "                                                        \n",
    "def compute_metrics_plaintext(results):\n",
    "    predictions = results['Prediction']\n",
    "    labels = results['Reference']\n",
    "    gleu = gleu_score.compute(predictions=predictions, references=[[l] for l in labels])\n",
    "    gleu = {k:round(v,6) for k,v in gleu.items()}\n",
    "    gleu['Gleu'] = gleu.pop('google_bleu')\n",
    "    bscore = bertscore.compute(predictions=predictions, references=labels, lang='en')\n",
    "    bscore['Bs-P'] = np.mean(np.array(bscore.pop('precision'))).round(6)\n",
    "    bscore['Bs-R'] = np.mean(np.array(bscore.pop('recall'))).round(6)\n",
    "    bscore['Bs-F1'] = np.mean(np.array(bscore.pop('f1'))).round(6)\n",
    "    bscore.pop('hashcode')\n",
    "    metrics = {**bscore, **gleu}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6ad37-c4cb-446f-8e50-8aaa6fcebdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_data_path)\n",
    "eval_data = pd.read_csv(test_data_path)\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "eval_dataset = Dataset.from_pandas(eval_data)\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "eval_dataset = eval_dataset.map(tokenize, batched=True)\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\",\"labels\"])\n",
    "eval_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\",\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ceabf9-c6eb-4ba4-8482-43b507533c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "timestr = now.strftime('%Y%m%d-%H%M')\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"/data2T/jingchuan/tuned/gen/{model_name}_{timestr}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=lr,\n",
    "    lr_scheduler_type=lr_schedule,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=8,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch'\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    seq2seqmodel,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c05dc2-d61f-4a2f-9a2e-e66dc6150eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_outputs = trainer.train()\n",
    "now = datetime.now()\n",
    "timestr = now.strftime('%Y%m%d-%H%M')\n",
    "training_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d4eb1-785e-46e6-addc-4bdee05950b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer(example):\n",
    "    reformatted_example = {k:v for k,v in example.items() if k in ['input_ids','attention_mask','labels']}\n",
    "    reformatted_example = [{k:v[i] for k,v in reformatted_example.items()} for i in range(len(example['input_ids']))]\n",
    "    inputs = data_collator(reformatted_example)\n",
    "    outputs = seq2seqmodel.generate(inputs['input_ids'].to(device),max_length=max_gen_length)\n",
    "    predictions = tokenizer.batch_decode(outputs.cpu().numpy(), skip_special_tokens=True)\n",
    "    return {'Input':tokenizer.batch_decode(example['input_ids'], skip_special_tokens=True), 'Reference':tokenizer.batch_decode(example['labels'], skip_special_tokens=True), 'Prediction':predictions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff5f3c-8ce1-41e4-8529-21814a548480",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = eval_dataset.map(infer,batched=True,batch_size=64,remove_columns=eval_dataset.column_names).to_pandas()\n",
    "eval_results['Prediction'] = eval_results['Prediction']\n",
    "metrics = compute_metrics_plaintext(eval_results)\n",
    "print(f'Model: {model_name}-{timestr}')\n",
    "print(metrics)\n",
    "display(eval_results)\n",
    "eval_results.to_csv(f'./../results/gen/{timestr}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55941f16-b3bc-45e7-9881-707ef729acc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seqmodel.save_pretrained(f'/data2T/jingchuan/tuned/gen/{model_name}-{timestr}-sota')\n",
    "tokenizer.save_pretrained(f'/data2T/jingchuan/tuned/gen/{model_name}-{timestr}-sota')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
