{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "371e4970-b607-49a2-af82-ccaa7a2fd9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + '/..')\n",
    "sys.path.append(os.getcwd() + '/../..')\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, Seq2SeqTrainer\n",
    "from datasets import Dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7b7ce6-d23a-445e-9f01-a57c68f7b7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7eff2ed109b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path = './../../data/gen/ebay_us-train.csv'\n",
    "test_data_path = './../../data/gen/ebay_us-test.csv'\n",
    "model_checkpoint = \"/data2T/jingchuan/tuned/gen/flan-t5-base_20231208-1351/checkpoint-10931/\"\n",
    "model_name = model_checkpoint.split(\"/\")[-2]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_batch_size = 8\n",
    "eval_batch_size = 32\n",
    "num_train_epochs = 8\n",
    "lr = 1e-5\n",
    "lr_schedule='linear'\n",
    "max_gen_length = 64\n",
    "np.random.seed(114514)\n",
    "torch.manual_seed(114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd9d6b5-3fd1-4a36-949e-7ba434e88792",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seqmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint,model_max_length=128)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=seq2seqmodel,padding=True)\n",
    "bertscore = evaluate.load('bertscore')\n",
    "gleu_score = evaluate.load(\"google_bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8f8726-5c82-412a-9e12-e5d612ee5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    model_inputs = tokenizer(examples[\"text\"])\n",
    "    labels = tokenizer(examples[\"summary\"])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0460d703-a242-4e6b-8d4a-12dc8c518275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    gleu = gleu_score.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])\n",
    "    gleu['Gleu'] = gleu.pop('google_bleu')\n",
    "    bscore = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang='en')\n",
    "    bscore['Bs-P'] = np.mean(np.array(bscore.pop('precision'))).round(6)\n",
    "    bscore['Bs-R'] = np.mean(np.array(bscore.pop('recall'))).round(6)\n",
    "    bscore['Bs-F1'] = np.mean(np.array(bscore.pop('f1'))).round(6)\n",
    "    bscore.pop('hashcode')\n",
    "    result = {**bscore, **gleu}\n",
    "    return {k: round(v, 6) for k, v in result.items()}\n",
    "                                                        \n",
    "def compute_metrics_plaintext(results):\n",
    "    predictions = results['Prediction']\n",
    "    labels = results['Reference']\n",
    "    gleu = gleu_score.compute(predictions=predictions, references=[[l] for l in labels])\n",
    "    gleu = {k:round(v,6) for k,v in gleu.items()}\n",
    "    gleu['Gleu'] = gleu.pop('google_bleu')\n",
    "    bscore = bertscore.compute(predictions=predictions, references=labels, lang='en')\n",
    "    bscore['Bs-P'] = np.mean(np.array(bscore.pop('precision'))).round(6)\n",
    "    bscore['Bs-R'] = np.mean(np.array(bscore.pop('recall'))).round(6)\n",
    "    bscore['Bs-F1'] = np.mean(np.array(bscore.pop('f1'))).round(6)\n",
    "    bscore.pop('hashcode')\n",
    "    metrics = {**bscore, **gleu}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c6ad37-c4cb-446f-8e50-8aaa6fcebdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa85187662c49b79d8dbf263258e6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20553 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c398616f92ec485ba04d015442fef436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2283 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_data_path)\n",
    "eval_data = pd.read_csv(test_data_path)\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "eval_dataset = Dataset.from_pandas(eval_data)\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "eval_dataset = eval_dataset.map(tokenize, batched=True)\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\",\"labels\"])\n",
    "eval_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\",\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ceabf9-c6eb-4ba4-8482-43b507533c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "timestr = now.strftime('%Y%m%d-%H%M')\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"/data2T/jingchuan/tuned/gen/{model_name}_{timestr}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=lr,\n",
    "    lr_scheduler_type=lr_schedule,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=8,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch'\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    seq2seqmodel,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1c05dc2-d61f-4a2f-9a2e-e66dc6150eef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10280' max='10280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10280/10280 7:28:35, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bs-p</th>\n",
       "      <th>Bs-r</th>\n",
       "      <th>Bs-f1</th>\n",
       "      <th>Gleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.496500</td>\n",
       "      <td>0.441173</td>\n",
       "      <td>0.964593</td>\n",
       "      <td>0.962788</td>\n",
       "      <td>0.963542</td>\n",
       "      <td>0.598019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.477900</td>\n",
       "      <td>0.438278</td>\n",
       "      <td>0.965140</td>\n",
       "      <td>0.963454</td>\n",
       "      <td>0.964151</td>\n",
       "      <td>0.604361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>0.428093</td>\n",
       "      <td>0.965313</td>\n",
       "      <td>0.963583</td>\n",
       "      <td>0.964300</td>\n",
       "      <td>0.604230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.447200</td>\n",
       "      <td>0.425803</td>\n",
       "      <td>0.965335</td>\n",
       "      <td>0.964002</td>\n",
       "      <td>0.964525</td>\n",
       "      <td>0.605386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.437900</td>\n",
       "      <td>0.421037</td>\n",
       "      <td>0.965543</td>\n",
       "      <td>0.964296</td>\n",
       "      <td>0.964778</td>\n",
       "      <td>0.610057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.430100</td>\n",
       "      <td>0.419362</td>\n",
       "      <td>0.965804</td>\n",
       "      <td>0.964412</td>\n",
       "      <td>0.964965</td>\n",
       "      <td>0.611327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.423300</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.965504</td>\n",
       "      <td>0.964394</td>\n",
       "      <td>0.964806</td>\n",
       "      <td>0.610288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.421100</td>\n",
       "      <td>0.419539</td>\n",
       "      <td>0.965799</td>\n",
       "      <td>0.964590</td>\n",
       "      <td>0.965053</td>\n",
       "      <td>0.613549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jingchuan/anaconda3/envs/ICON/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10280, training_loss=0.4493949266723158, metrics={'train_runtime': 26932.6927, 'train_samples_per_second': 6.105, 'train_steps_per_second': 0.382, 'total_flos': 9360690516882432.0, 'train_loss': 0.4493949266723158, 'epoch': 8.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_outputs = trainer.train()\n",
    "now = datetime.now()\n",
    "timestr = now.strftime('%Y%m%d-%H%M')\n",
    "training_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "568d4eb1-785e-46e6-addc-4bdee05950b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer(example):\n",
    "    reformatted_example = {k:v for k,v in example.items() if k in ['input_ids','attention_mask','labels']}\n",
    "    reformatted_example = [{k:v[i] for k,v in reformatted_example.items()} for i in range(len(example['input_ids']))]\n",
    "    inputs = data_collator(reformatted_example)\n",
    "    outputs = seq2seqmodel.generate(inputs['input_ids'].to(device),max_length=max_gen_length)\n",
    "    predictions = tokenizer.batch_decode(outputs.cpu().numpy(), skip_special_tokens=True)\n",
    "    return {'Input':tokenizer.batch_decode(example['input_ids'], skip_special_tokens=True), 'Reference':tokenizer.batch_decode(example['labels'], skip_special_tokens=True), 'Prediction':predictions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69ff5f3c-8ce1-41e4-8529-21814a548480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5f310ca7764ac79dc769c9c4578ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2283 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: checkpoint-10931-20231209-0719\n",
      "{'Bs-P': 0.965864, 'Bs-R': 0.964687, 'Bs-F1': 0.965134, 'Gleu': 0.616313}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summarize: Original Beanie Babies; Retired Ty ...</td>\n",
       "      <td>Ty Beanbag Plushies</td>\n",
       "      <td>Beanbag Plushies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summarize: Needlepoint Kits; Ribbon Embroidery...</td>\n",
       "      <td>Hand Embroidery Sets &amp; Kits</td>\n",
       "      <td>Embroidery &amp; Cross Stitch Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summarize: Ethnic Americana Collectibles; Coll...</td>\n",
       "      <td>Ethnic &amp; Cultural Collectibles</td>\n",
       "      <td>Ethnic &amp; Cultural Collectibles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summarize: Industrial Rock, Gravel &amp; Sand; Ind...</td>\n",
       "      <td>Industrial Cement, Concrete &amp; Masonry</td>\n",
       "      <td>Industrial Building Materials &amp; Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>summarize: Bowling Clothing; Youth Bowling Clo...</td>\n",
       "      <td>Bowling Clothing</td>\n",
       "      <td>Bowling Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>summarize: Game Used NFL Jerseys; Game Used NF...</td>\n",
       "      <td>Root Concept</td>\n",
       "      <td>Root Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>summarize: Industrial Wood Composite Panels &amp; ...</td>\n",
       "      <td>Root Concept</td>\n",
       "      <td>Root Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>summarize: Other Tesla Cars &amp; Trucks; Tesla Ro...</td>\n",
       "      <td>Root Concept</td>\n",
       "      <td>Root Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>summarize: Women's Golf Socks; Women's Golf Co...</td>\n",
       "      <td>Root Concept</td>\n",
       "      <td>Root Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>summarize: Hordes War Games; Other Warmachine ...</td>\n",
       "      <td>Root Concept</td>\n",
       "      <td>Root Concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2283 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input  \\\n",
       "0     summarize: Original Beanie Babies; Retired Ty ...   \n",
       "1     summarize: Needlepoint Kits; Ribbon Embroidery...   \n",
       "2     summarize: Ethnic Americana Collectibles; Coll...   \n",
       "3     summarize: Industrial Rock, Gravel & Sand; Ind...   \n",
       "4     summarize: Bowling Clothing; Youth Bowling Clo...   \n",
       "...                                                 ...   \n",
       "2278  summarize: Game Used NFL Jerseys; Game Used NF...   \n",
       "2279  summarize: Industrial Wood Composite Panels & ...   \n",
       "2280  summarize: Other Tesla Cars & Trucks; Tesla Ro...   \n",
       "2281  summarize: Women's Golf Socks; Women's Golf Co...   \n",
       "2282  summarize: Hordes War Games; Other Warmachine ...   \n",
       "\n",
       "                                  Reference  \\\n",
       "0                       Ty Beanbag Plushies   \n",
       "1               Hand Embroidery Sets & Kits   \n",
       "2            Ethnic & Cultural Collectibles   \n",
       "3     Industrial Cement, Concrete & Masonry   \n",
       "4                          Bowling Clothing   \n",
       "...                                     ...   \n",
       "2278                           Root Concept   \n",
       "2279                           Root Concept   \n",
       "2280                           Root Concept   \n",
       "2281                           Root Concept   \n",
       "2282                           Root Concept   \n",
       "\n",
       "                                    Prediction  \n",
       "0                             Beanbag Plushies  \n",
       "1           Embroidery & Cross Stitch Supplies  \n",
       "2               Ethnic & Cultural Collectibles  \n",
       "3     Industrial Building Materials & Supplies  \n",
       "4                             Bowling Clothing  \n",
       "...                                        ...  \n",
       "2278                              Root Concept  \n",
       "2279                              Root Concept  \n",
       "2280                              Root Concept  \n",
       "2281                              Root Concept  \n",
       "2282                              Root Concept  \n",
       "\n",
       "[2283 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = eval_dataset.map(infer,batched=True,batch_size=64,remove_columns=eval_dataset.column_names).to_pandas()\n",
    "eval_results['Prediction'] = eval_results['Prediction']\n",
    "metrics = compute_metrics_plaintext(eval_results)\n",
    "print(f'Model: {model_name}-{timestr}')\n",
    "print(metrics)\n",
    "display(eval_results)\n",
    "eval_results.to_csv(f'./../results/gen/{timestr}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55941f16-b3bc-45e7-9881-707ef729acc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/data2T/jingchuan/tuned/gen/flan-t5-sota/tokenizer_config.json',\n",
       " '/data2T/jingchuan/tuned/gen/flan-t5-sota/special_tokens_map.json',\n",
       " '/data2T/jingchuan/tuned/gen/flan-t5-sota/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seqmodel.save_pretrained(f'/data2T/jingchuan/tuned/gen/{model_name}-{timestr}-sota')\n",
    "tokenizer.save_pretrained(f'/data2T/jingchuan/tuned/gen/{model_name}-{timestr}-sota')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
