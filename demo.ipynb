{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d10dff60-49d0-47a6-828c-937eec5a79b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: SQLite3 version 3.40.0 and 3.41.2 have huge performance regressions; please install version 3.41.1 or 3.42!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Union\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from simcse import SimCSE\n",
    "from transformers import BertForSequenceClassification, AutoModelForSeq2SeqLM, BertTokenizer, AutoTokenizer\n",
    "from utils import taxo_utils\n",
    "from utils.taxo_utils import Taxonomy\n",
    "from main.icon import ICON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e495a24e-6126-4bb4-907b-aefbdce9c0d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ret_model = SimCSE('/data2T/jingchuan/tuned/ret/entity_type_tuned_sota/',device=device)\n",
    "gen_model = AutoModelForSeq2SeqLM.from_pretrained('/data2T/jingchuan/tuned/gen/flan-t5-sota/').to(device)\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained('/data2T/jingchuan/tuned/gen/flan-t5-sota/')\n",
    "sub_model = BertForSequenceClassification.from_pretrained('/data2T/jingchuan/tuned/sub/bertsubs-sota/').to(device)\n",
    "sub_tokenizer = BertTokenizer.from_pretrained('/data2T/jingchuan/tuned/sub/bertsubs-sota/',model_max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1edbdea1-25a3-4000-b687-c91029617976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxo = taxo_utils.from_json('./data/raw/ebay_us.json')\n",
    "df = pd.DataFrame(taxo.nodes(data='label'),columns=['ID','Label']).drop(0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc1afbb-18cc-453b-b787-747a3f580251",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict = {}\n",
    "idx_dict = {}\n",
    "for i,row in df.iterrows():\n",
    "    idx_dict[i] = row['ID']\n",
    "    id_dict[row['ID']] = i\n",
    "def index_to_ID(x):\n",
    "    return idx_dict[x]\n",
    "def ID_to_index(id):\n",
    "    return id_dict[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d060cdda-38b8-4abb-bb11-b8d9c29269e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_model.build_index(list(df['Label']))\n",
    "def RET_model(taxo: Taxonomy, query: str, k=10):\n",
    "    topk = ret_model.search(query, top_k=k)\n",
    "    return [index_to_ID(i) for i,_,_ in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0adce056-0c0e-46bb-a9db-443b8671b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GEN_model(labels,prefix='summarize: '):\n",
    "    corpus = prefix\n",
    "    for l in labels:\n",
    "        corpus += l + '; '\n",
    "    corpus = corpus[:-2]\n",
    "    inputs = gen_tokenizer(corpus,return_tensors='pt').to(device)['input_ids']\n",
    "    outputs = gen_model.generate(inputs,max_length=64)[0]\n",
    "    decoded = gen_tokenizer.decode(outputs.cpu().numpy(),skip_special_tokens=True)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15943f32-0b14-4f6c-9204-9affece1e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SUB_model(sub: Union[str, List[str]], sup: Union[str, List[str]], batch_size :int=256):\n",
    "    if isinstance(sub, str):\n",
    "        sub, sup = [sub], [sup]\n",
    "    if len(sub) <= batch_size:\n",
    "        inputs = sub_tokenizer(sub,sup,padding=True,return_tensors='pt').to(device)\n",
    "        predictions = torch.softmax(sub_model(**inputs).logits.detach().cpu(),1)[:,1].numpy()\n",
    "    else:\n",
    "        head = (sub[:batch_size], sup[:batch_size])\n",
    "        tail = (sub[batch_size:],sup[batch_size:])\n",
    "        predictions = np.concatenate((SUB_model(head[0], head[1], batch_size=batch_size), SUB_model(tail[0], tail[1], batch_size=batch_size)))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77fac59b-a9f5-4e24-a463-160967c6401b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5fbc9541d4447dc9adc427538d19586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading lexical cache:   0%|          | 0/20334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kwargs = {'data': taxo,\n",
    "        'ret_model': RET_model,\n",
    "        'gen_model': GEN_model,\n",
    "        'sub_model': SUB_model,\n",
    "        'mode': 'manual',\n",
    "        'auto_bases': True,\n",
    "        'input_concepts': ['plastic round tubes', 'pipe wrenches', 'mixed lots', 'mountain lions', 'opticals', 'port expansion cards', 'eagles', 'drawer slides', 'steel drums', 'softballs'],\n",
    "        'restrict_combinations': False,\n",
    "        'retrieve_size': 5,\n",
    "        'threshold': 0.95,\n",
    "        'do_update': False,\n",
    "        'logging': True}\n",
    "\n",
    "newobj = ICON(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1baf83f8-74c2-4214-af6f-8b3aed46a3b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kwargs = {'data': taxo,\n",
    "#         'ret_model': RET_model,\n",
    "#         'gen_model': GEN_model,\n",
    "#         'sub_model': SUB_model,\n",
    "#         'mode': 'auto',\n",
    "#         'semiauto_seeds': [175781],\n",
    "#         'restrict_combinations': True,\n",
    "#         'retrieve_size': 2,\n",
    "#         'threshold': 0.9,\n",
    "#         'log': 1}\n",
    "\n",
    "# newobj = icon.ICON(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e8edbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Taxonomy with 20334 nodes and 20333 edges. Commencing enrichment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6e8ee4ee3f401aacc18e028334d056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enrichment complete. Begin post-processing with transitive reduction\n",
      "Return ICON predictions\n"
     ]
    }
   ],
   "source": [
    "outputs = newobj.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
