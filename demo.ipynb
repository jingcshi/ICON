{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d10dff60-49d0-47a6-828c-937eec5a79b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: SQLite3 version 3.40.0 and 3.41.2 have huge performance regressions; please install version 3.41.1 or 3.42!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Union, Tuple\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from simcse import SimCSE\n",
    "from transformers import BertForSequenceClassification, AutoModelForSeq2SeqLM, BertTokenizer, AutoTokenizer\n",
    "from utils import taxo_utils\n",
    "from utils.taxo_utils import Taxonomy\n",
    "from main.icon import ICON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e495a24e-6126-4bb4-907b-aefbdce9c0d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ret_model = SimCSE('/data2T/jingchuan/tuned/ret/entity_type_tuned_sota/',device=device)\n",
    "gen_model = AutoModelForSeq2SeqLM.from_pretrained('/data2T/jingchuan/tuned/gen/flan-t5-sota/').to(device)\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained('/data2T/jingchuan/tuned/gen/flan-t5-sota/')\n",
    "sub_model = BertForSequenceClassification.from_pretrained('/data2T/jingchuan/tuned/sub/bertsubs-sota/').to(device)\n",
    "sub_tokenizer = BertTokenizer.from_pretrained('/data2T/jingchuan/tuned/sub/bertsubs-sota/',model_max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1edbdea1-25a3-4000-b687-c91029617976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxo = taxo_utils.from_json('./data/raw/ebay_us.json')\n",
    "df = pd.DataFrame(taxo.nodes(data='label'),columns=['ID','Label']).drop(0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc1afbb-18cc-453b-b787-747a3f580251",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict = {}\n",
    "idx_dict = {}\n",
    "for i,row in df.iterrows():\n",
    "    idx_dict[i] = row['ID']\n",
    "    id_dict[row['ID']] = i\n",
    "def index_to_ID(x):\n",
    "    return idx_dict[x]\n",
    "def ID_to_index(id):\n",
    "    return id_dict[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d060cdda-38b8-4abb-bb11-b8d9c29269e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_model.build_index(list(df['Label']))\n",
    "def RET_model(taxo:Taxonomy,seed:Union[int,str],k=10):\n",
    "    if isinstance(seed,int):\n",
    "        seed = taxo.get_label(seed)\n",
    "    topk = ret_model.search(seed,top_k=k)\n",
    "    return [index_to_ID(i) for i,_,_ in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0adce056-0c0e-46bb-a9db-443b8671b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GEN_model(labels,prefix='summarize: '):\n",
    "    corpus = prefix\n",
    "    for l in labels:\n",
    "        corpus += l + '; '\n",
    "    corpus = corpus[:-2]\n",
    "    inputs = gen_tokenizer(corpus,return_tensors='pt').to(device)['input_ids']\n",
    "    outputs = gen_model.generate(inputs,max_length=64)[0]\n",
    "    decoded = gen_tokenizer.decode(outputs.cpu().numpy(),skip_special_tokens=True)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15943f32-0b14-4f6c-9204-9affece1e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SUB_model(sub: Union[str, List[str]], sup: Union[str, List[str]], batch_size :int=256):\n",
    "    if isinstance(sub, str):\n",
    "        sub, sup = [sub], [sup]\n",
    "    if len(sub) <= batch_size:\n",
    "        inputs = sub_tokenizer(sub,sup,padding=True,return_tensors='pt').to(device)\n",
    "        predictions = torch.softmax(sub_model(**inputs).logits.detach().cpu(),1)[:,1].numpy()\n",
    "    else:\n",
    "        head = (sub[:batch_size], sup[:batch_size])\n",
    "        tail = (sub[batch_size:],sup[batch_size:])\n",
    "        predictions = np.concatenate((SUB_model(head[0], head[1], batch_size=batch_size), SUB_model(tail[0], tail[1], batch_size=batch_size)))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77fac59b-a9f5-4e24-a463-160967c6401b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b9fa366c554285855ced470bb0cc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading lexical cache:   0%|          | 0/20334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kwargs = {'data': taxo,\n",
    "        'ret_model': RET_model,\n",
    "        'gen_model': GEN_model,\n",
    "        'sub_model': SUB_model,\n",
    "        'mode': 'manual',\n",
    "        'input_concepts': ['plastic round tubes', 'pipe wrenches', 'mixed lots', 'mountain lions', 'opticals', 'port expansion cards', 'eagles', 'drawer slides', 'steel drums', 'softballs'],\n",
    "        'restrict_combinations': False,\n",
    "        'retrieve_size': 5,\n",
    "        'threshold': 0.9,\n",
    "        'log': True}\n",
    "\n",
    "newobj = ICON(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1baf83f8-74c2-4214-af6f-8b3aed46a3b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kwargs = {'data': taxo,\n",
    "#         'ret_model': RET_model,\n",
    "#         'gen_model': GEN_model,\n",
    "#         'sub_model': SUB_model,\n",
    "#         'mode': 'auto',\n",
    "#         'semiauto_seeds': [175781],\n",
    "#         'restrict_combinations': True,\n",
    "#         'retrieve_size': 2,\n",
    "#         'threshold': 0.9,\n",
    "#         'log': 1}\n",
    "\n",
    "# newobj = icon.ICON(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e8edbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Taxonomy with 20334 nodes and 20333 edges. Commencing enrichment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6868a0dab84c7b9bf42af78d849b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tInput: \u001b[36m\u001b[1mplastic round tubes\u001b[0m\n",
      "\t\t\tSearching on a domain of 20334 classes\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnewobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ICON/main/icon.py:216\u001b[0m, in \u001b[0;36mICON.run\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39msub_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub_model is required to run manual mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with transitive reduction\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtransitive_reduction \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    219\u001b[0m progress_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Added \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFore\u001b[38;5;241m.\u001b[39mBLACK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mStyle\u001b[38;5;241m.\u001b[39mBRIGHT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mprogress[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mStyle\u001b[38;5;241m.\u001b[39mRESET_ALL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m new classes and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFore\u001b[38;5;241m.\u001b[39mBLACK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mStyle\u001b[38;5;241m.\u001b[39mBRIGHT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mprogress[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mStyle\u001b[38;5;241m.\u001b[39mRESET_ALL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m new direct subsumptions.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mupdate_config\u001b[38;5;241m.\u001b[39mdo_update \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/ICON/main/icon.py:299\u001b[0m, in \u001b[0;36mICON.manual\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFore\u001b[38;5;241m.\u001b[39mCYAN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mStyle\u001b[38;5;241m.\u001b[39mBRIGHT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnewlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mStyle\u001b[38;5;241m.\u001b[39mRESET_ALL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mouter_loop_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 299\u001b[0m inner_loop_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_bases\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mprogress \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m inner_loop_progress\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mpbar_outer:\n",
      "File \u001b[0;32m~/ICON/main/icon.py:606\u001b[0m, in \u001b[0;36mICON.inner_loop\u001b[0;34m(self, newlabel, base)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearching on a domain of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubgraph_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m classes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter_details\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# Search for optimal placement using the SUB model to predict subsumption.\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m sup, sub, eqv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menhanced_traversal\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubtaxo\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnewlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m resolution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexical_check(newlabel) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mupdate_config\u001b[38;5;241m.\u001b[39mdo_lexical_check \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolution:\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;66;03m# We give 100% confidence to the linkage of NIL model, thus making it supercede any other possible equivalences provided by search\u001b[39;00m\n",
      "File \u001b[0;32m~/ICON/main/icon.py:420\u001b[0m, in \u001b[0;36mICON.enhanced_traversal\u001b[0;34m(self, taxo, newlabel, base)\u001b[0m\n\u001b[1;32m    418\u001b[0m queue \u001b[38;5;241m=\u001b[39m deque([(n,\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m bottom])\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bottom:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_sub_score_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaxo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbottom\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnewlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbottom\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# The redundant superclasses are also logically certain to be non-subclasses, so we do not search on them\u001b[39;00m\n\u001b[1;32m    422\u001b[0m visited \u001b[38;5;241m=\u001b[39m {k:\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m sup_ancestors}\n",
      "File \u001b[0;32m~/ICON/main/icon.py:156\u001b[0m, in \u001b[0;36mICON.update_sub_score_cache\u001b[0;34m(self, sub, sup)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_sub_score_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m, sub: List[\u001b[38;5;28mstr\u001b[39m], sup: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# The model output is expected to be a numpy.array of shape [len(keypair)]\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(outputs):\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaches\u001b[38;5;241m.\u001b[39msub_score_cache[(sub[i], sup[i])] \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36mSUB_model\u001b[0;34m(sub, sup, batch_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m     head \u001b[38;5;241m=\u001b[39m (sub[:batch_size], sup[:batch_size])\n\u001b[1;32m      9\u001b[0m     tail \u001b[38;5;241m=\u001b[39m (sub[batch_size:],sup[batch_size:])\n\u001b[0;32m---> 10\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((\u001b[43msub_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m, sub_model(tail[\u001b[38;5;241m0\u001b[39m], tail[\u001b[38;5;241m1\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39mbatch_size)))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/anaconda3/envs/ICON/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ICON/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'batch_size'"
     ]
    }
   ],
   "source": [
    "newobj.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
